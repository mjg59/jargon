 :Moore's Law: /morz law/, prov. Any one of several similar folk theorems
that fit computing capacity or cost to a 2^t exponential curve, with doubling
time close to a year. The most common fits component density to such a curve
(previous versions of this entry gave that form). Another variant asserts
that the dollar cost of constant computing power decreases on the same curve.
The original Moore's Law, first uttered in 1965 by semiconductor engineer
Gordon Moore (who co-founded Intel four years later), spoke of the number of
components on the lowest-cost silicon integrated circuits -- but Moore's own
formulation varied somewhat over the years, and reconstructing the meaning of
the terminology he used in the original turns out to be fraught with
difficulties. Further variants were spawned by Intel's PR department and
various journalists. It has been shown that none of the variants of Moore's
Law actually fit the data very well (the price curves within DRAM generations
perhaps come closest). Nevertheless, Moore's Law is constantly invoked to set
up expectations about the next generation of computing technology. see also
{Parkinson's Law of Data} and {Gates's Law}.